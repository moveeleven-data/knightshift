version: "3.9"   # docker‑compose schema version
# ─────────────────────────────────────────────────────────────
#  KnightShift stack:  Postgres 17  +  custom pipeline image
#                      +  Apache Airflow for orchestration
# ─────────────────────────────────────────────────────────────

x-common-env: &common_env   # 🔗 anchor reused by multiple services
  PGHOST:     ${PGHOST}
  PGPORT:     ${PGPORT}
  PGDATABASE: ${PGDATABASE}
  PGUSER:     ${PGUSER}
  PGPASSWORD: ${PGPASSWORD}

  AWS_ACCESS_KEY_ID:     ${AWS_ACCESS_KEY_ID}
  AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
  AWS_DEFAULT_REGION:    ${AWS_DEFAULT_REGION}
  DB_SECRET_NAME:        ${DB_SECRET_NAME}

services:
# ─────────────────────────────────────────────────────────────
  db:
    image: postgres:17
    restart: always
    environment:
      POSTGRES_USER:     ${PGUSER}
      POSTGRES_PASSWORD: ${PGPASSWORD}
      POSTGRES_DB:       ${PGDATABASE}
    ports:
      # expose container‑5432 on localhost:55432 (avoids clashing with
      # a host Postgres installation)
      - "127.0.0.1:55432:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./schemas:/docker-entrypoint-initdb.d   # boot‑time SQL seeds

# ─────────────────────────────────────────────────────────────
  pipeline:
    build: .
    depends_on: [db]
    environment: *common_env      # ← expands the anchor defined above
    volumes:
      - ./logs:/app/logs          # persistent pipeline logs
    command: ["bash", "run.sh"]

# ─────────────────────────────────────────────────────────────
  airflow:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    restart: always
    depends_on:
      - db
    environment:
      <<: *common_env
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:postgres@db:5432/knightshift
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "True"
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      RUNNING_IN_DOCKER: "true"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./src:/app/src
      - ./config:/app/config
    ports:
      - "8080:8080"
    # ← Replace your old `command:` here with this:
    command: >
      bash -c "
        # migrate the metadata DB
        airflow db upgrade &&
        # create the admin user if not exists (|| true so it won’t fail if already there)
        airflow users create \
          --username admin \
          --password admin \
          --firstname admin \
          --lastname admin \
          --role Admin \
          --email admin@example.com \
          --use-random-password=false || true &&
        # start the scheduler in the background
        airflow scheduler & 
        # exec the webserver on 0.0.0.0:8080
        exec airflow webserver --host 0.0.0.0 --port 8080
      "

# ─────────────────────────────────────────────────────────────
volumes:
  pg_data:   # named volume → survives container rebuilds
