ðŸ“ˆ Project Progress â€“ KnightShift

A running log of major development milestones, current state, and future plans for the KnightShift data pipeline.
                   
--------------------------------- 

## May 2, 2025 â€“ Grafana Dashboard and Prometheus Integration
Incorporated Grafana to monitor key metrics, creating a dashboard that tracks games ingested over time, broken down by job. Metrics include the 95th percentile of request duration, total HTTP requests, HTTP requests with status 200, and the average request duration histogram. An email alert was also set up to notify when there is at least one HTTP error.

Prometheus was successfully integrated, with key metrics tracked through the ingestion script, including HTTP request totals, errors, and latencies, as well as ingestion metrics like the number of games ingested, added, and updated. Additional metrics were configured for tracking ingestion duration and overall performance, with aggregations grouped by instance and job.
         
---------------------------------    

## May 1, 2025 â€“ Test Automation and GitHub CI Integration
Enhanced the CI/CD pipeline by creating two test scripts and integrating them with GitHub Actions for continuous integration. These tests ensure key functionalities, such as game validation and user profile backfilling, work as expected, including validation of TV channel game data and backfill_user_profiles pulling from the Lichess API.

Added additional checks to the validation script to catch edge cases and data anomalies, further improving system robustness. Configured GitHub Actions to run these tests automatically on each push to the master branch, ensuring early detection of potential issues.

---------------------------------    

## April 29, 2025 â€“ Backup Automation and Safety Infrastructure

Implemented a production-aware, beginner-friendly backup system for the KnightShift PostgreSQL database using a 
custom backup.sh script and cron. The script runs pg_dump inside the Docker container via docker exec, compresses the output, logs to backups/backup.log, and automatically cleans up files older than 7 days. It was moved to the project root, made executable, added to version control, and paired with a cron job scheduled for 2:00 AM daily. We also excluded backups/ via .gitignore and recommended ShellCheck for linting.

In parallel, we refactored the entire database schema to adopt a consistent column naming convention (e.g., white â†’ id_user_white, result â†’ val_result, ingested_at â†’ tm_ingested). Scripts were updated accordinglyâ€”get_games_from_tv.py, validate_tv_channel_games.py, and backfill_user_profiles.pyâ€”with changes to metadata models and logic to reflect the new schema. The system was rebuilt from scratch (docker compose down -v && up --build), and Airflowâ€™s full DAG pipeline passed all tasks successfully.

A versioned migration file (2025-05-01__rename_columns.sql) was added under schemas/ and enforced via a pre-commit hook. All changes were documented in docs/schema_mappings.md, and a Git tag v0.2.0-pre-refactor was created for rollback safety. Finally, PyCharm was configured to connect to the Dockerized Postgres instance for live schema inspection, completing a robust, future-ready setup for Phase 2.

---------------------------------
                          
## April 25, 2025 â€“ Environment Configuration Standardization

Refactored environment variable management by standardizing on a single `.env` file at the project root. Added a `.
env.template` in `config/` to provide a safe, version-controlled reference for required keys. Updated `db_utils.py` 
to load environment variables properly, prioritizing container-level overrides for local and containerized runs. Cleaned up and reorganized `.gitignore` to exclude sensitive files (`.env`, `annotations/`), improving project security and hygiene. Verified that the KnightShift ingestion DAG runs cleanly after the migration.

## April 16, 2025 â€“ Airflow Integration Complete

We successfully transitioned the KnightShift pipeline to run fully through Apache Airflow using Docker Compose. All scriptsâ€”ingestion, cleaning, enrichmentâ€”now run as Airflow tasks, and the web UI confirms their success. Major hurdles included incorrect Docker networking (PGHOST was set to localhost instead of db), environment variable confusion, and Python version mismatches (e.g., using set[str] in Python 3.8). Debugging inside containers and streamlining the environment config made the difference. The pipeline now runs reliably under Airflow, which gives us a production-style orchestration backbone moving forward.

## April 12, 2025 â€“ Fully Containerized Storage & Environment Stability

PostgreSQL was fully containerized, with scripts reading secrets from AWS Secrets Manager and using different environment configs for local and Docker contexts. We verified that scripts and containers communicate properly across networks, and that schemas auto-initialize on container startup. Logging was routed to pipeline.log, schema logic was centralized, and we cleaned up obsolete databases. We also renamed updated to is_validated for clarity and dropped redundant flags, ensuring all cleaning logic is robust and semantic.

## April 1, 2025 â€“ Modularized Execution and Testing Foundations

We split the monolithic main.py into three separate scripts for ingestion, cleaning, and enrichment. Each can now run independently or through Airflow. We added README.md files across all folders, cleaned up old scripts into a legacy/ directory, and created version-controlled schemas. Unit tests were added for all key logic (PGN parsing, DB utils, upserting), improving reliability and debuggability. Logging and Git hygiene were also improved.

## March 31, 2025 â€“ Structure Overhaul and Data Cleaning Expansion

Restructured the codebase into clear domains: ingestion, cleaning, enrichment, archive, and utils. Refactored user enrichment scripts and added missing data checks in validation. Cleaned invalid rows and marked records using new validation flags. Documentation and config consistency were improved across the board.

## March 30, 2025 â€“ API Hardening and Rate Limit Handling

Introduced persistent session handling and graceful exits on API rate limits. Improved the user enrichment script with batch pausing, error handling, and connection pooling. All key game-related scripts were updated for better performance and safety. Table schemas were documented more clearly, including primary keys and indexes.

## March 25, 2025 â€“ Lichess User Profile Enrichment

Built a new script to pull public profile data from Lichess and store it in a new table, lichess_users. Used smart logic to only fetch data for unprocessed users and track progress with a profile_updated flag. This enrichment pipeline ensures the database has rich, detailed player-level information.

## March 24, 2025 â€“ Docker Connectivity Fixes and Secrets Management

Fixed PostgreSQL connection issues by overriding the host inside Docker. Used Docker Compose for orchestration and confirmed full pipeline functionality inside containers. Environment separation (.env.local vs .env.docker) was finalized, and all sensitive credentials were centralized using AWS Secrets Manager. Successfully ran and logged end-to-end runs using docker run.

## December 2024 â€“ Initial Ingestion System Launched

Developed the first version of the KnightShift pipeline. Scripts were built to fetch Lichess game data from both TV streams and user profiles. Parsed and inserted the data into Postgres, with enrichment logic to avoid duplicate updates. This laid the foundation for the more robust modular system we have today.
